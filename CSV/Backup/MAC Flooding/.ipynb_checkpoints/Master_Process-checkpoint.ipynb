{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29108d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First process is Cleaning, and there's two version of Cleaning dataset\n",
    "## because there's different it data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First version data cleaning for normal traffic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c38605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import socket\n",
    "import struct\n",
    "import ipaddress\n",
    "\n",
    "filename = sys.argv[1]\n",
    "file1 = pd.read_csv(filename)\n",
    "file1.head(10)\n",
    "file1.isnull().sum\n",
    "#print(file1.isnull().sum)\n",
    "# step-1 to replace all null\n",
    "update_file = file1.fillna(\" \")\n",
    "update_file.isnull().sum()\n",
    "#print (update_file.isnull().sum()) \n",
    "update_file.to_csv('update_'+filename, index = False)\n",
    "# step-2 to remove all rows with null value\n",
    "update_file = file1.fillna(0)\n",
    "#print (update_file.isnull().sum())\n",
    "# step-3 to convert tcp.flag, ip.dst, ip.src to integer\n",
    "# (unused)update_file['tcp.flags'] = update_file['tcp.flags'].apply(lambda x: int(str(x), 16))\n",
    "update_file['ip.dst'] = update_file['ip.dst'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file['ip.src'] = update_file['ip.src'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file.to_csv('update_'+filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second data cleaning format is to clean intrusion dataset that has used tcp.flags in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75947d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import socket\n",
    "import struct\n",
    "import ipaddress\n",
    "import macaddress\n",
    "\n",
    "filename = sys.argv[1]\n",
    "file1 = pd.read_csv(filename)\n",
    "file1.head(10)\n",
    "file1.isnull().sum\n",
    "#print(file1.isnull().sum)\n",
    "# step-1 to replace all null\n",
    "update_file = file1.fillna(\" \")\n",
    "update_file.isnull().sum()\n",
    "#print (update_file.isnull().sum()) \n",
    "update_file.to_csv('update_'+filename, index = False)\n",
    "# step-2 to remove all rows with null value\n",
    "update_file = file1.fillna(0)\n",
    "#print (update_file.isnull().sum())\n",
    "# step-3 to convert tcp.flag, ip.dst, ip.src to integer\n",
    "# (unused)update_file['tcp.flags'] = update_file['tcp.flags'].apply(lambda x: int(str(x), 16))\n",
    "update_file['ip.dst'] = update_file['ip.dst'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file['ip.src'] = update_file['ip.src'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file['eth.addr'] = update_file['eth.addr'].apply(lambda x: int(macaddress.EUI48(x)))\n",
    "update_file['eth.dst'] = update_file['eth.dst'].apply(lambda x: int(macaddress.EUI48(x)))\n",
    "update_file.to_csv('update_'+filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de1e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "9# Create a list containing the index numbers you want to remove\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import socket\n",
    "import struct\n",
    "import ipaddress\n",
    "\n",
    "\n",
    "df = pd.read_csv('Labeled_update_MAC_Flooding_attack.csv')\n",
    "\n",
    "\n",
    "index_list = list(range(10482, 19338))\n",
    "df.drop(df.index[index_list], inplace =True)\n",
    "df.shape\n",
    "df\n",
    "df.to_csv('Labeled_update_MAC_Flooding_attack.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af664bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second process is to label the dataset with Normal_Traffic and Abnormal_Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "\n",
    "label = sys.argv[1]\n",
    "file_name = sys.argv[2]\n",
    "\n",
    "file = open(file_name)\n",
    "content = csv.reader(file)\n",
    "#row0 = content.next() for python2 and next(content) for python 3\n",
    "row0 = next(content)\n",
    "row0.append('label')\n",
    "all = []\n",
    "all.append(row0)\n",
    "for item in content:\n",
    "    item.append(label)\n",
    "    all.append(item)\n",
    "\n",
    "new_file = open(\"Labeled_\" + file_name, 'w')\n",
    "writer = csv.writer(new_file, lineterminator='\\n')\n",
    "writer.writerows(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3dd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3rd Proces is to create a master dataset by combine both normal traffic \n",
    "## and intrusion traffic for MAC attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f63ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultant CSV after joining all CSV files at a particular location...\n",
      "           ip.src      ip.dst         eth.addr          eth.dst  \\\n",
      "0        98035027  3253489514  115848086057608  115848086057608   \n",
      "1      1347488552  1542973513  188194502993945  188194502993945   \n",
      "2      2053479744  1092413464    4754214429298    4754214429298   \n",
      "3      3908210972  2355885408  149069977429158  149069977429158   \n",
      "4       692955396  2660973117   86080524491827   86080524491827   \n",
      "...           ...         ...              ...              ...   \n",
      "20958  3232235777  3232235778   13259053006848   13259053006848   \n",
      "20959           0           0  281474976710655  281474976710655   \n",
      "20960           0           0  281474976710655  281474976710655   \n",
      "20961           0           0    1652522221568    1652522221568   \n",
      "20962           0           0  281474976710655  281474976710655   \n",
      "\n",
      "       frame.time_relative  frame.time_delta             label  \n",
      "0                 0.000000          0.000000  Abnormal_Traffic  \n",
      "1                 0.000385          0.000385  Abnormal_Traffic  \n",
      "2                 0.002072          0.001687  Abnormal_Traffic  \n",
      "3                 0.002424          0.000352  Abnormal_Traffic  \n",
      "4                 0.007847          0.005423  Abnormal_Traffic  \n",
      "...                    ...               ...               ...  \n",
      "20958          5035.897557          0.014194    Normal_Traffic  \n",
      "20959          5035.898868          0.001311    Normal_Traffic  \n",
      "20960          5036.893622          0.994754    Normal_Traffic  \n",
      "20961          5037.372030          0.478408    Normal_Traffic  \n",
      "20962          5037.888027          0.515997    Normal_Traffic  \n",
      "\n",
      "[20963 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# setting the path for joining multiple files\n",
    "files = os.path.join(\"C:/Users/Admin/Desktop/CSV file/T Shark extract/4.Completed Store/MAC Flooding\",\"Labeled*.csv\")\n",
    "\n",
    "# list of merged files returned\n",
    "files = glob.glob(files)\n",
    "\n",
    "print(\"Resultant CSV after joining all CSV files at a particular location...\");\n",
    "\n",
    "# joining files with concat and read_csv\n",
    "df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "print(df)\n",
    "\n",
    "df.to_csv('Master_MAC_Attack.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b045ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Ununsed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3846658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip.src      ip.dst  ip.len  ip.flags.df  ip.ttl  ip.proto  \\\n",
      "0              0           0     0.0          0.0     0.0       0.0   \n",
      "1              0           0     0.0          0.0     0.0       0.0   \n",
      "2              0           0     0.0          0.0     0.0       0.0   \n",
      "3              0           0     0.0          0.0     0.0       0.0   \n",
      "4              0           0     0.0          0.0     0.0       0.0   \n",
      "...          ...         ...     ...          ...     ...       ...   \n",
      "1237  3232235778  3232235780    84.0          1.0    64.0       1.0   \n",
      "1238  3232235780  3232235778    84.0          0.0    64.0       1.0   \n",
      "1239           0           0     0.0          0.0     0.0       0.0   \n",
      "1240           0           0     0.0          0.0     0.0       0.0   \n",
      "1241           0           0     0.0          0.0     0.0       0.0   \n",
      "\n",
      "      frame.time_relative  frame.time_delta           label  \n",
      "0                0.000000          0.000000   DHCP_Spoofing  \n",
      "1                0.754911          0.754911   DHCP_Spoofing  \n",
      "2                1.096345          0.341434   DHCP_Spoofing  \n",
      "3                1.106258          0.009913   DHCP_Spoofing  \n",
      "4                2.974673          1.868415   DHCP_Spoofing  \n",
      "...                   ...               ...             ...  \n",
      "1237           257.749137          0.002468  Normal_Traffic  \n",
      "1238           257.755494          0.006357  Normal_Traffic  \n",
      "1239           258.576457          0.820963  Normal_Traffic  \n",
      "1240           258.627872          0.051415  Normal_Traffic  \n",
      "1241           258.628271          0.000399  Normal_Traffic  \n",
      "\n",
      "[1242 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "#read dataset\n",
    "data = pd.read_csv('Master_MAC_Attack.csv')\n",
    "\n",
    "# display\n",
    "#print(data)\n",
    "  \n",
    "# pop function which is used in removing or deleting columns from the CSV files\n",
    "data.pop('ip.flags.mf')\n",
    "data.pop('ip.fragment')\n",
    "data.pop('ip.fragment.count')\n",
    "data.pop('ip.fragments')\n",
    "data.pop('tcp.window_size')\n",
    "data.pop('tcp.ack')\n",
    "data.pop('tcp.seq')\n",
    "data.pop('tcp.len')\n",
    "data.pop('tcp.stream')\n",
    "data.pop('tcp.urgent_pointer')\n",
    "data.pop('tcp.flags')\n",
    "data.pop('tcp.analysis.ack_rtt')\n",
    "data.pop('tcp.segments')\n",
    "data.pop('tcp.reassembled.length')\n",
    "data.pop('http.request')\n",
    "data.pop('udp.port')\n",
    "data.pop('tcp.time_relative')\n",
    "data.pop('tcp.time_delta')\n",
    "         \n",
    "  \n",
    "# display\n",
    "print(data)\n",
    "data.to_csv('Master_MAC_Attack.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4040a",
   "metadata": {},
   "source": [
    "## last step is to train with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfa2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d70dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98035027 3253489514 115848086057608 ... 0.0 0.0 'Abnormal_Traffic']\n",
      " [1347488552 1542973513 188194502993945 ... 0.000385 0.000385\n",
      "  'Abnormal_Traffic']\n",
      " [2053479744 1092413464 4754214429298 ... 0.002072 0.001687\n",
      "  'Abnormal_Traffic']\n",
      " ...\n",
      " [0 0 281474976710655 ... 5036.893622 0.994754 'Normal_Traffic']\n",
      " [0 0 1652522221568 ... 5037.37203 0.478408 'Normal_Traffic']\n",
      " [0 0 281474976710655 ... 5037.888027 0.515997 'Normal_Traffic']]\n",
      "LR Accuracy: 0.499046 (+/- 0.006155)\n",
      "LDA Accuracy: 0.912430 (+/- 0.004364)\n",
      "KNN Accuracy: 0.997751 (+/- 0.000462)\n",
      "CART Accuracy: 0.999319 (+/- 0.000482)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CART results on 30% test set \n",
      "\n",
      "0.9988644106291165\n",
      "\n",
      "CART accuracy test: \n",
      "\n",
      "0.9988644106291165\n",
      "[[2194    4]\n",
      " [   1 2204]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      2198\n",
      "  Normal_Traffic       1.00      1.00      1.00      2205\n",
      "\n",
      "        accuracy                           1.00      4403\n",
      "       macro avg       1.00      1.00      1.00      4403\n",
      "    weighted avg       1.00      1.00      1.00      4403\n",
      "\n",
      "\n",
      "CART results on final 30% validation \n",
      "\n",
      "\n",
      "CART accuracy validation: \n",
      "\n",
      "0.9993639688344729\n",
      "[[3158    1]\n",
      " [   3 3127]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      3159\n",
      "  Normal_Traffic       1.00      1.00      1.00      3130\n",
      "\n",
      "        accuracy                           1.00      6289\n",
      "       macro avg       1.00      1.00      1.00      6289\n",
      "    weighted avg       1.00      1.00      1.00      6289\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " Logistic Regression results on 30% test set \n",
      "\n",
      "0.49920508744038156\n",
      "\n",
      "Logistic Regression accuracy test: \n",
      "\n",
      "0.49920508744038156\n",
      "[[2198    0]\n",
      " [2205    0]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.50      1.00      0.67      2198\n",
      "  Normal_Traffic       0.00      0.00      0.00      2205\n",
      "\n",
      "        accuracy                           0.50      4403\n",
      "       macro avg       0.25      0.50      0.33      4403\n",
      "    weighted avg       0.25      0.50      0.33      4403\n",
      "\n",
      "\n",
      "Logistic Regression results on final 30% validation \n",
      "\n",
      "\n",
      "Logistic Regression accuracy validation: \n",
      "\n",
      "0.9993639688344729\n",
      "[[3158    1]\n",
      " [   3 3127]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      3159\n",
      "  Normal_Traffic       1.00      1.00      1.00      3130\n",
      "\n",
      "        accuracy                           1.00      6289\n",
      "       macro avg       1.00      1.00      1.00      6289\n",
      "    weighted avg       1.00      1.00      1.00      6289\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " KNeighbors results on 30% test set \n",
      "\n",
      "0.9975017033840563\n",
      "\n",
      "K Neighbors accuracy test: \n",
      "\n",
      "0.9975017033840563\n",
      "[[2187   11]\n",
      " [   0 2205]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      0.99      1.00      2198\n",
      "  Normal_Traffic       1.00      1.00      1.00      2205\n",
      "\n",
      "        accuracy                           1.00      4403\n",
      "       macro avg       1.00      1.00      1.00      4403\n",
      "    weighted avg       1.00      1.00      1.00      4403\n",
      "\n",
      "\n",
      "K Neighbors results on final 30% validation \n",
      "\n",
      "\n",
      "K Neighbors accuracy validation: \n",
      "\n",
      "0.9993639688344729\n",
      "[[3158    1]\n",
      " [   3 3127]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      3159\n",
      "  Normal_Traffic       1.00      1.00      1.00      3130\n",
      "\n",
      "        accuracy                           1.00      6289\n",
      "       macro avg       1.00      1.00      1.00      6289\n",
      "    weighted avg       1.00      1.00      1.00      6289\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " Linear Discriminant Analysis results on 30% test set \n",
      "\n",
      "0.9114240290710879\n",
      "\n",
      "Linear Discriminant Analysis accuracy test: \n",
      "\n",
      "0.9114240290710879\n",
      "[[2198    0]\n",
      " [ 390 1815]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.85      1.00      0.92      2198\n",
      "  Normal_Traffic       1.00      0.82      0.90      2205\n",
      "\n",
      "        accuracy                           0.91      4403\n",
      "       macro avg       0.92      0.91      0.91      4403\n",
      "    weighted avg       0.92      0.91      0.91      4403\n",
      "\n",
      "\n",
      "Linear Discriminant Analysis results on final 30% validation \n",
      "\n",
      "\n",
      "Linear Discriminant Analysis accuracy validation: \n",
      "\n",
      "0.9993639688344729\n",
      "[[3158    1]\n",
      " [   3 3127]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      3159\n",
      "  Normal_Traffic       1.00      1.00      1.00      3130\n",
      "\n",
      "        accuracy                           1.00      6289\n",
      "       macro avg       1.00      1.00      1.00      6289\n",
      "    weighted avg       1.00      1.00      1.00      6289\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " Logistic Regression results on 30% test set \n",
      "\n",
      "0.49920508744038156\n",
      "\n",
      "Logistic Regression accuracy test: \n",
      "\n",
      "0.49920508744038156\n",
      "[[2198    0]\n",
      " [2205    0]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.50      1.00      0.67      2198\n",
      "  Normal_Traffic       0.00      0.00      0.00      2205\n",
      "\n",
      "        accuracy                           0.50      4403\n",
      "       macro avg       0.25      0.50      0.33      4403\n",
      "    weighted avg       0.25      0.50      0.33      4403\n",
      "\n",
      "\n",
      "Logistic Regression results on final 30% validation \n",
      "\n",
      "\n",
      "Logistic Regression accuracy validation: \n",
      "\n",
      "0.9993639688344729\n",
      "[[3158    1]\n",
      " [   3 3127]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      3159\n",
      "  Normal_Traffic       1.00      1.00      1.00      3130\n",
      "\n",
      "        accuracy                           1.00      6289\n",
      "       macro avg       1.00      1.00      1.00      6289\n",
      "    weighted avg       1.00      1.00      1.00      6289\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " KNeighbors results on 30% test set \n",
      "\n",
      "0.9975017033840563\n",
      "\n",
      "K Neighbors accuracy test: \n",
      "\n",
      "0.9975017033840563\n",
      "[[2187   11]\n",
      " [   0 2205]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      0.99      1.00      2198\n",
      "  Normal_Traffic       1.00      1.00      1.00      2205\n",
      "\n",
      "        accuracy                           1.00      4403\n",
      "       macro avg       1.00      1.00      1.00      4403\n",
      "    weighted avg       1.00      1.00      1.00      4403\n",
      "\n",
      "\n",
      "K Neighbors results on final 30% validation \n",
      "\n",
      "\n",
      "K Neighbors accuracy validation: \n",
      "\n",
      "0.9993639688344729\n",
      "[[3158    1]\n",
      " [   3 3127]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      3159\n",
      "  Normal_Traffic       1.00      1.00      1.00      3130\n",
      "\n",
      "        accuracy                           1.00      6289\n",
      "       macro avg       1.00      1.00      1.00      6289\n",
      "    weighted avg       1.00      1.00      1.00      6289\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " Linear Discriminant Analysis results on 30% test set \n",
      "\n",
      "0.9114240290710879\n",
      "\n",
      "Linear Discriminant Analysis accuracy test: \n",
      "\n",
      "0.9114240290710879\n",
      "[[2198    0]\n",
      " [ 390 1815]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.85      1.00      0.92      2198\n",
      "  Normal_Traffic       1.00      0.82      0.90      2205\n",
      "\n",
      "        accuracy                           0.91      4403\n",
      "       macro avg       0.92      0.91      0.91      4403\n",
      "    weighted avg       0.92      0.91      0.91      4403\n",
      "\n",
      "\n",
      "Linear Discriminant Analysis results on final 30% validation \n",
      "\n",
      "\n",
      "Linear Discriminant Analysis accuracy validation: \n",
      "\n",
      "0.9993639688344729\n",
      "[[3158    1]\n",
      " [   3 3127]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       1.00      1.00      1.00      3159\n",
      "  Normal_Traffic       1.00      1.00      1.00      3130\n",
      "\n",
      "        accuracy                           1.00      6289\n",
      "       macro avg       1.00      1.00      1.00      6289\n",
      "    weighted avg       1.00      1.00      1.00      6289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from six import StringIO \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os   \n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "# import dataset\n",
    "dataset = pandas.read_csv(\"Master_MAC_Attack.csv\")\n",
    "\n",
    "#print (dataset.shape)\n",
    "\n",
    "# head\n",
    "#print(dataset.head(20))\n",
    "\n",
    "# descriptions\n",
    "#print(dataset.describe())\n",
    "\n",
    "# class distribution\n",
    "#print(dataset.groupby('label').size())\n",
    "\n",
    "# split dataset\n",
    "array = dataset.values\n",
    "print (array)\n",
    "X = array[:,0:6]\n",
    "Y = array[:,6]\n",
    "validation_size = 0.30\n",
    "seed = 42\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "X_train_set, X_test, Y_train_set, Y_test = model_selection.train_test_split(X_train, Y_train, test_size=validation_size, random_state=seed)\n",
    "\n",
    "\n",
    "# Test options and evaluation metric\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Fit algorithm model\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s Accuracy: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "\n",
    "#Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n CART results on 30% test set \\n\")\n",
    "# Create Decision Tree classifer object\n",
    "cart = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "cart.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'decision_finalized_DT_model.sav'\n",
    "joblib.dump(cart, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = cart.predict(X_test)\n",
    "print(\"\\nCART accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nCART results on final 30% validation \\n\")\n",
    "newcart = DecisionTreeClassifier()\n",
    "newcart.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newcart.predict(X_validation)\n",
    "print(\"\\nCART accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n",
    "\n",
    "# Testing For Logistic Regression\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n Logistic Regression results on 30% test set \\n\")\n",
    "# Create Logistic Regression classifer object\n",
    "logistic = LogisticRegression()\n",
    "# Train Logistic Regression Classifer\n",
    "logistic.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'logistic_finalized_DT_model.sav'\n",
    "joblib.dump(logistic, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = logistic.predict(X_test)\n",
    "print(\"\\nLogistic Regression accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc, zero_division=0))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nLogistic Regression results on final 30% validation \\n\")\n",
    "newlogistic = DecisionTreeClassifier()\n",
    "newlogistic.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newlogistic.predict(X_validation)\n",
    "print(\"\\nLogistic Regression accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n",
    "\n",
    "# Testing For KNeighbors\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n KNeighbors results on 30% test set \\n\")\n",
    "# Create K Neighbors classifer object\n",
    "KNeighbors = KNeighborsClassifier()\n",
    "# Train KNeighbors Classifer\n",
    "KNeighbors.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'kneighbors_finalized_DT_model.sav'\n",
    "joblib.dump(KNeighbors, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = KNeighbors.predict(X_test)\n",
    "print(\"\\nK Neighbors accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc, zero_division=0))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nK Neighbors results on final 30% validation \\n\")\n",
    "newKNeighbors = DecisionTreeClassifier()\n",
    "newKNeighbors.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newKNeighbors.predict(X_validation)\n",
    "print(\"\\nK Neighbors accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n",
    "\n",
    "# Testing For Linear Discriminant Analysis\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n Linear Discriminant Analysis results on 30% test set \\n\")\n",
    "# Create Logistic Regression classifer object\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "# Train Linear Discriminant Analysis Classifer\n",
    "lda.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'lda_finalized_DT_model.sav'\n",
    "joblib.dump(lda, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = lda.predict(X_test)\n",
    "print(\"\\nLinear Discriminant Analysis accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc, zero_division=0))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nLinear Discriminant Analysis results on final 30% validation \\n\")\n",
    "newlda = DecisionTreeClassifier()\n",
    "newlda.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newlda.predict(X_validation)\n",
    "print(\"\\nLinear Discriminant Analysis accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9faba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045fb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
