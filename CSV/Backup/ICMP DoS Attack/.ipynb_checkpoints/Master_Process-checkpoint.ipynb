{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29108d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First process is Cleaning, and there's two version of Cleaning dataset\n",
    "## because there's different it data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First version data cleaning for normal traffic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c38605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import socket\n",
    "import struct\n",
    "import ipaddress\n",
    "\n",
    "filename = sys.argv[1]\n",
    "file1 = pd.read_csv(filename)\n",
    "file1.head(10)\n",
    "file1.isnull().sum\n",
    "#print(file1.isnull().sum)\n",
    "# step-1 to replace all null\n",
    "update_file = file1.fillna(\" \")\n",
    "update_file.isnull().sum()\n",
    "#print (update_file.isnull().sum()) \n",
    "update_file.to_csv('update_'+filename, index = False)\n",
    "# step-2 to remove all rows with null value\n",
    "update_file = file1.fillna(0)\n",
    "#print (update_file.isnull().sum())\n",
    "# step-3 to convert tcp.flag, ip.dst, ip.src to integer\n",
    "# (unused)update_file['tcp.flags'] = update_file['tcp.flags'].apply(lambda x: int(str(x), 16))\n",
    "update_file['ip.dst'] = update_file['ip.dst'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file['ip.src'] = update_file['ip.src'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file.to_csv('update_'+filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second data cleaning format is to clean intrusion dataset that has used tcp.flags in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75947d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import socket\n",
    "import struct\n",
    "import ipaddress\n",
    "\n",
    "filename = sys.argv[1]\n",
    "file1 = pd.read_csv(filename)\n",
    "file1.head(10)\n",
    "file1.isnull().sum\n",
    "#print(file1.isnull().sum)\n",
    "# step-1 to replace all null\n",
    "update_file = file1.fillna(\" \")\n",
    "update_file.isnull().sum()\n",
    "#print (update_file.isnull().sum()) \n",
    "update_file.to_csv('update_'+filename, index = False)\n",
    "# step-2 to remove all rows with null value\n",
    "update_file = file1.fillna(0)\n",
    "#print (update_file.isnull().sum())\n",
    "# step-3 to convert tcp.flag, ip.dst, ip.src to integer\n",
    "update_file['tcp.flags'] = update_file['tcp.flags'].apply(lambda x: int(str(x), 16))\n",
    "update_file['ip.dst'] = update_file['ip.dst'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file['ip.src'] = update_file['ip.src'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "update_file.to_csv('update_'+filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de1e6b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1778 is out of bounds for axis 0 with size 1778",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate_Normal_Traffic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m index_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1778\u001b[39m, \u001b[38;5;241m10480\u001b[39m))\n\u001b[1;32m---> 15\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_list\u001b[49m\u001b[43m]\u001b[49m, inplace \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     17\u001b[0m df\n",
      "File \u001b[1;32mD:\\Users\\sookinchun\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py:942\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly integers, slices (`:`), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mellipsis (`...`), numpy.newaxis (`None`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand integer or boolean \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrays are valid indices\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    940\u001b[0m     )\n\u001b[0;32m    941\u001b[0m \u001b[38;5;66;03m# fall back to Int64Index\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\sookinchun\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5055\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   5049\u001b[0m     \u001b[38;5;66;03m# if we have list[bools, length=1e5] then doing this check+convert\u001b[39;00m\n\u001b[0;32m   5050\u001b[0m     \u001b[38;5;66;03m#  takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__\u001b[39;00m\n\u001b[0;32m   5051\u001b[0m     \u001b[38;5;66;03m#  time below from 3.8 ms to 496 µs\u001b[39;00m\n\u001b[0;32m   5052\u001b[0m     \u001b[38;5;66;03m# if we already have ndarray[bool], the overhead is 1.4 µs or .25%\u001b[39;00m\n\u001b[0;32m   5053\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 5055\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5056\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1778 is out of bounds for axis 0 with size 1778"
     ]
    }
   ],
   "source": [
    "# Create a list containing the index numbers you want to remove\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import socket\n",
    "import struct\n",
    "import ipaddress\n",
    "\n",
    "\n",
    "df = pd.read_csv('update_Normal_Traffic.csv')\n",
    "\n",
    "\n",
    "index_list = list(range(1779, 10480))\n",
    "df.drop(df.index[index_list], inplace =True)\n",
    "df.shape\n",
    "df\n",
    "df.to_csv('update_Normal_Traffic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af664bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second process is to label the dataset with Normal_Traffic and Abnormal_Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "\n",
    "label = sys.argv[1]\n",
    "file_name = sys.argv[2]\n",
    "\n",
    "file = open(file_name)\n",
    "content = csv.reader(file)\n",
    "#row0 = content.next() for python2 and next(content) for python 3\n",
    "row0 = next(content)\n",
    "row0.append('label')\n",
    "all = []\n",
    "all.append(row0)\n",
    "for item in content:\n",
    "    item.append(label)\n",
    "    all.append(item)\n",
    "\n",
    "new_file = open(\"Labeled_\" + file_name, 'w')\n",
    "writer = csv.writer(new_file, lineterminator='\\n')\n",
    "writer.writerows(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3dd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3rd Proces is to create a master dataset by combine both normal traffic \n",
    "## and intrusion traffic for DoS attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f63ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultant CSV after joining all CSV files at a particular location...\n",
      "          ip.src      ip.dst  ip.len  ip.flags.df  ip.flags.mf  ip.fragment  \\\n",
      "0              0           0     0.0          0.0          0.0          0.0   \n",
      "1              0           0     0.0          0.0          0.0          0.0   \n",
      "2              0           0     0.0          0.0          0.0          0.0   \n",
      "3              0           0     0.0          0.0          0.0          0.0   \n",
      "4              0           0     0.0          0.0          0.0          0.0   \n",
      "...          ...         ...     ...          ...          ...          ...   \n",
      "3550           0           0     0.0          0.0          0.0          0.0   \n",
      "3551  3232235778  3232235780    84.0          1.0          0.0          0.0   \n",
      "3552  3232235780  3232235778    84.0          0.0          0.0          0.0   \n",
      "3553  3232235778  3232235779    84.0          1.0          0.0          0.0   \n",
      "3554  3232235779  3232235778    84.0          0.0          0.0          0.0   \n",
      "\n",
      "      ip.fragment.count  ip.fragments  ip.ttl  ip.proto  ...  \\\n",
      "0                   0.0           0.0     0.0       0.0  ...   \n",
      "1                   0.0           0.0     0.0       0.0  ...   \n",
      "2                   0.0           0.0     0.0       0.0  ...   \n",
      "3                   0.0           0.0     0.0       0.0  ...   \n",
      "4                   0.0           0.0     0.0       0.0  ...   \n",
      "...                 ...           ...     ...       ...  ...   \n",
      "3550                0.0           0.0     0.0       0.0  ...   \n",
      "3551                0.0           0.0    64.0       1.0  ...   \n",
      "3552                0.0           0.0    64.0       1.0  ...   \n",
      "3553                0.0           0.0    64.0       1.0  ...   \n",
      "3554                0.0           0.0   128.0       1.0  ...   \n",
      "\n",
      "      tcp.analysis.ack_rtt  tcp.segments  tcp.reassembled.length  \\\n",
      "0                      0.0           0.0                     0.0   \n",
      "1                      0.0           0.0                     0.0   \n",
      "2                      0.0           0.0                     0.0   \n",
      "3                      0.0           0.0                     0.0   \n",
      "4                      0.0           0.0                     0.0   \n",
      "...                    ...           ...                     ...   \n",
      "3550                   0.0           0.0                     0.0   \n",
      "3551                   0.0           0.0                     0.0   \n",
      "3552                   0.0           0.0                     0.0   \n",
      "3553                   0.0           0.0                     0.0   \n",
      "3554                   0.0           0.0                     0.0   \n",
      "\n",
      "      http.request  udp.port  frame.time_relative  frame.time_delta  \\\n",
      "0              0.0       0.0             0.000000          0.000000   \n",
      "1              0.0       0.0             2.091256          2.091256   \n",
      "2              0.0       0.0             4.159467          2.068211   \n",
      "3              0.0       0.0             6.215494          2.056027   \n",
      "4              0.0       0.0             8.267153          2.051659   \n",
      "...            ...       ...                  ...               ...   \n",
      "3550           0.0       0.0           728.292775          1.953421   \n",
      "3551           0.0       0.0           728.337658          0.044883   \n",
      "3552           0.0       0.0           728.340893          0.003235   \n",
      "3553           0.0       0.0           728.342223          0.001330   \n",
      "3554           0.0       0.0           728.346230          0.004007   \n",
      "\n",
      "      tcp.time_relative  tcp.time_delta             label  \n",
      "0                   0.0             0.0  Abnormal_Traffic  \n",
      "1                   0.0             0.0  Abnormal_Traffic  \n",
      "2                   0.0             0.0  Abnormal_Traffic  \n",
      "3                   0.0             0.0  Abnormal_Traffic  \n",
      "4                   0.0             0.0  Abnormal_Traffic  \n",
      "...                 ...             ...               ...  \n",
      "3550                0.0             0.0    Normal_traffic  \n",
      "3551                0.0             0.0    Normal_traffic  \n",
      "3552                0.0             0.0    Normal_traffic  \n",
      "3553                0.0             0.0    Normal_traffic  \n",
      "3554                0.0             0.0    Normal_traffic  \n",
      "\n",
      "[3555 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# setting the path for joining multiple files\n",
    "files = os.path.join(\"C:/Users/Admin/Desktop/CSV file/T Shark extract/4.Completed Store/ICMP DoS Attack\",\"Labeled*.csv\")\n",
    "\n",
    "# list of merged files returned\n",
    "files = glob.glob(files)\n",
    "\n",
    "print(\"Resultant CSV after joining all CSV files at a particular location...\");\n",
    "\n",
    "# joining files with concat and read_csv\n",
    "df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "print(df)\n",
    "\n",
    "df.to_csv('Master_ICMP_Attack.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b045ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Ununsed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3846658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip.src      ip.dst  ip.len  ip.flags.df  ip.ttl  ip.proto  \\\n",
      "0              0           0     0.0          0.0     0.0       0.0   \n",
      "1              0           0     0.0          0.0     0.0       0.0   \n",
      "2              0           0     0.0          0.0     0.0       0.0   \n",
      "3              0           0     0.0          0.0     0.0       0.0   \n",
      "4              0           0     0.0          0.0     0.0       0.0   \n",
      "...          ...         ...     ...          ...     ...       ...   \n",
      "1237  3232235778  3232235780    84.0          1.0    64.0       1.0   \n",
      "1238  3232235780  3232235778    84.0          0.0    64.0       1.0   \n",
      "1239           0           0     0.0          0.0     0.0       0.0   \n",
      "1240           0           0     0.0          0.0     0.0       0.0   \n",
      "1241           0           0     0.0          0.0     0.0       0.0   \n",
      "\n",
      "      frame.time_relative  frame.time_delta           label  \n",
      "0                0.000000          0.000000   DHCP_Spoofing  \n",
      "1                0.754911          0.754911   DHCP_Spoofing  \n",
      "2                1.096345          0.341434   DHCP_Spoofing  \n",
      "3                1.106258          0.009913   DHCP_Spoofing  \n",
      "4                2.974673          1.868415   DHCP_Spoofing  \n",
      "...                   ...               ...             ...  \n",
      "1237           257.749137          0.002468  Normal_Traffic  \n",
      "1238           257.755494          0.006357  Normal_Traffic  \n",
      "1239           258.576457          0.820963  Normal_Traffic  \n",
      "1240           258.627872          0.051415  Normal_Traffic  \n",
      "1241           258.628271          0.000399  Normal_Traffic  \n",
      "\n",
      "[1242 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "#read dataset\n",
    "data = pd.read_csv('Master_ICMP_Attack.csv')\n",
    "\n",
    "# display\n",
    "#print(data)\n",
    "  \n",
    "# pop function which is used in removing or deleting columns from the CSV files\n",
    "data.pop('ip.flags.mf')\n",
    "data.pop('ip.fragment')\n",
    "data.pop('ip.fragment.count')\n",
    "data.pop('ip.fragments')\n",
    "data.pop('tcp.window_size')\n",
    "data.pop('tcp.ack')\n",
    "data.pop('tcp.seq')\n",
    "data.pop('tcp.len')\n",
    "data.pop('tcp.stream')\n",
    "data.pop('tcp.urgent_pointer')\n",
    "data.pop('tcp.flags')\n",
    "data.pop('tcp.analysis.ack_rtt')\n",
    "data.pop('tcp.segments')\n",
    "data.pop('tcp.reassembled.length')\n",
    "data.pop('http.request')\n",
    "data.pop('udp.port')\n",
    "data.pop('tcp.time_relative')\n",
    "data.pop('tcp.time_delta')\n",
    "         \n",
    "  \n",
    "# display\n",
    "print(data)\n",
    "data.to_csv('Master_ICMP_Attack.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4040a",
   "metadata": {},
   "source": [
    "## last step is to train with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfa2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d70dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0.0 ... 0.0 0.0 'Abnormal_Traffic']\n",
      " [0 0 0.0 ... 2.091256 2.091256 'Abnormal_Traffic']\n",
      " [0 0 0.0 ... 4.159467 2.068211 'Abnormal_Traffic']\n",
      " ...\n",
      " [3232235780 3232235778 84.0 ... 728.340893 0.003235 'Normal_traffic']\n",
      " [3232235778 3232235779 84.0 ... 728.342223 0.00133 'Normal_traffic']\n",
      " [3232235779 3232235778 84.0 ... 728.34623 0.004007 'Normal_traffic']]\n",
      "LR Accuracy: 0.652729 (+/- 0.010867)\n",
      "LDA Accuracy: 0.906766 (+/- 0.017474)\n",
      "KNN Accuracy: 0.992769 (+/- 0.006791)\n",
      "CART Accuracy: 0.993169 (+/- 0.005329)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaH0lEQVR4nO3df5xddX3n8debCcECSZgsI5YkkFgjJqAEvMbHloBEBIOtjdiuZqQr5hGb0uWHD+y6UMJDQt207rrUIsRNs5KyVJNIK6lxFyGuohCrNZMaID+IjuFHxkiZONEIyI+Ez/5xztDDzb0zJ8mduXe+eT8fj3lkzvl+v/d8zmF4z3e+995zFRGYmVm6jmp2AWZmNrQc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQ20GRdIek/zpEj32ppHUDtJ8vqWcojj3SSbpe0heaXYe1Jge91STp25L2SDpmuI4ZEV+KiIsKNYSkNwzX8ZW5WtJmSc9K6pH095LePFw1HKqI+IuI+Giz67DW5KC3A0iaDJwLBPB7w3TMUcNxnEHcAnwMuBoYD7wR+Efgd5pY06Ba5NpZC3PQWy0fBr4P3AFcNlBHSf9F0s8k7ZL00eIsXNI4SXdK6pX0hKQbJB2Vt31E0nclfVZSH7A437c+b38gP8RDkp6R9MHCMf9U0tP5cecX9t8h6fOSvp6P+a6k10n66/yvk0clnVXnPKYCVwCdEfGtiHghIp7L/8r49EGezy8k7ZD02/n+nXm9l1XVukzSNyT9StJ3JJ1aaL8lH7dX0kZJ5xbaFkv6B0lflLQX+Ei+74t5+2vytp/ntWyQdFLedrKktZL6JHVL+qOqx70rP8dfSdoiqTLQf38bGRz0VsuHgS/lX+/uD4lqkuYAHwfeBbwBeEdVl1uBccDr87YPA/ML7W8HdgCvBZYUB0bEefm3Z0bE8RHx5Xz7dfljTgAWAEsltReGfgC4ATgReAH4HvAv+fY/AH9V55wvAHoi4gd12suez8PAvwNWAquBt5Fdmz8EbpN0fKH/pcCn8to2kV3vfhuAGWR/WawE/l7Sawrtc/PzOaFqHGS/nMcBk/JaLgd+nbetAnqAk4E/AP5C0gWFsb+X130CsBa4rf7lsJHCQW+vImkWcCpwV0RsBH4CfKhO9w8AfxsRWyLiOeCmwuO0AR8E/iwifhURjwM3A/+xMH5XRNwaEfsi4teU8xLw5xHxUkTcAzwDnFZoXxMRGyPieWAN8HxE3BkR+4EvAzVn9GSB+LN6By15Po9FxN8WjjUpr/WFiFgHvEgW+v3+b0Q8EBEvAIuAfy9pEkBEfDEifp5fm5uBY6rO83sR8Y8R8XKNa/dSfj5viIj9+fXYmz/2LODaiHg+IjYBX6g6h/URcU9+Dn8HnFnvmtjI4aC3apcB6yJid769kvrLNycDOwvbxe9PBEYDTxT2PUE2E6/Vv6yfR8S+wvZzQHGW/K+F739dY7vY91WPC/zmAMctcz7VxyIiBjr+K+cfEc8AfWTXtH95apukX0r6BdkM/cRaY2v4O+A+YHW+pPbfJR2dP3ZfRPxqgHN4qvD9c8Br/BzAyOegt1dI+g2yWfo7JD0l6SngGuBMSbVmdj8DJha2JxW+3002szy1sO8U4KeF7Va6deo3gYkDrEmXOZ+D9cr1ypd0xgO78vX4a8n+W7RHxAnALwEVxta9dvlfOzdFxHTgt4HfJVtm2gWMlzSmgedgI4CD3oreB+wHppOtD88ApgEPkgVFtbuA+ZKmSToW+GR/Q/6n/13AEklj8icaPw588SDq+Vey9fAhFxE/Bj4PrFL2ev3R+ZOa8yRd16DzqfYeSbMkjSZbq//niNgJjAH2Ab3AKEmfBMaWfVBJsyW9OV9u2kv2C2p//tj/BPxlfm5vIXueo3qN3xLjoLeiy8jW3J+MiKf6v8iekLu0+k/4iPg68DngfqCb7IlPyJ4EBbgKeJbsCdf1ZMtAKw6insXA/85fOfKBQzyng3E12bkuBX5B9vzEJcDX8vbDPZ9qK4EbyZZs3kr25Cxkyy5fB35EtrTyPAe3zPU6sidq9wLbgO/wb7+QOoHJZLP7NcCNEfGNwzgHGwHkDx6xRpE0DdgMHFO1jm5VJN1B9iqfG5pdi6XPM3o7LJIuyZc52oH/BnzNIW/WWhz0drj+mGwt+Sdk6/t/0txyzKyal27MzBLnGb2ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiWvJT3c/8cQTY/Lkyc0uw8xsxNi4cePuiOio1daSQT958mS6urqaXYaZ2Ygh6Yl6bV66MTNLnIPezCxxDnozs8Q56M3MEuegNzNL3KBBL2mFpKclba7TLkmfk9Qt6WFJZxfa5kjanrdd18jCzexAq1at4owzzqCtrY0zzjiDVatWNbskawFlZvR3AHMGaL8YmJp/LQT+J4CkNmBp3j4d6JQ0/XCKNbP6Vq1axaJFi7j11lt5/vnnufXWW1m0aJHD3gYP+oh4AOgboMtc4M7IfB84QdJvAjOB7ojYEREvAqvzvmY2BJYsWcLtt9/O7NmzOfroo5k9eza33347S5YsaXZp1mSNeMPUBGBnYbsn31dr/9vrPYikhWR/EXDKKac0oCyzI8u2bduYNWvWq/bNmjWLbdu2Nami1iepoY8XEQ19vEZpxJOxta5UDLC/pohYHhGViKh0dNR8F6+ZDWDatGmsX7/+VfvWr1/PtGnTmlRR64uIUl9l+7aqRszoe4BJhe2JwC5gdJ39ZlbD+PHj2bNnz2E9xjvf+c6a+w9n5tre3k5f30Crt62pEdezqBGz/2Zdy0YE/VrgSkmryZZmfhkRP5PUC0yVNAX4KTAP+FADjmeWpL6r9wNjm11GDfubXcAhac3r2ZxrOWjQS1oFnA+cKKkHuBE4GiAilgH3AO8BuoHngPl52z5JVwL3AW3AiojYMgTnYJYE3bS32SXU1N7eTt/iZldx8HTT3pZbTpFELB7+4w4a9BHROUh7AFfUabuH7BeBmQ2i1UIpBY1+svVwtbe3N+W4fmesmSWp7BOtA32tXLmS008/naOOOorTTz+dlStXHtbjNeu5jpa8H72ZWbP1vwHt9ttvZ9asWaxfv54FCxYA0Nk54EJHy/GM3iwhvgVC46T0BjTP6M0SkdIMtBWk9AY0z+jNEpHSDLQVpPQGNAe9WSJSmoG2gkWLFrFgwQLuv/9+XnrpJe6//34WLFjAokWLml3aQfPSjVki+megs2fPfmXfSJ2BtoL+5a6rrrqKbdu2MW3aNJYsWTIil8Ec9GaJ6J+BVq/Re+nm0HV2do7IYK/moDdLREozUGssteK78SqVSnR1dTW7DDOzEUPSxoio1Grzk7FmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniSgW9pDmStkvqlnRdjfZ2SWskPSzpB5LOKLQ9LukRSZsk+V1QZmbDrMyHg7cBS4ELgR5gg6S1EbG10O16YFNEXCLpTXn/CwrtsyNidwPrNjOzksrM6GcC3RGxIyJeBFYDc6v6TAe+CRARjwKTJZ3U0ErNzOyQlAn6CcDOwnZPvq/oIeD9AJJmAqcCE/O2ANZJ2ihpYb2DSFooqUtSV29vb9n6zcxsEGWCXjX2Vd8J7dNAu6RNwFXAD4F9eds5EXE2cDFwhaTzah0kIpZHRCUiKh0dHaWKNzOzwZW5TXEPMKmwPRHYVewQEXuB+QCSBDyWfxERu/J/n5a0hmwp6IHDrtzMzEopM6PfAEyVNEXSaGAesLbYQdIJeRvAR4EHImKvpOMkjcn7HAdcBGxuXPlmZjaYQWf0EbFP0pXAfUAbsCIitki6PG9fBkwD7pS0H9gKLMiHnwSsySb5jAJWRsS9jT8NMzOrxx88YmaWAH/wiJnZEcxBb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJa7MTc3Maho/fjx79uxpdhkHaG9vp6+vr9llmLUMB70dsj179tCKt9DI761kZjkv3ZiZJc5Bb2aWOAe9mVnivEZvhyxuHAuLxzW7jAPEjWObXYJZS3HQ2yHTTXtb9snYWNzsKsxah5duzMwS56A3M0tcqaCXNEfSdkndkq6r0d4uaY2khyX9QNIZZceamdnQGjToJbUBS4GLgelAp6TpVd2uBzZFxFuADwO3HMRYMzMbQmVm9DOB7ojYEREvAquBuVV9pgPfBIiIR4HJkk4qOdbMzIZQmaCfAOwsbPfk+4oeAt4PIGkmcCowseRY8nELJXVJ6urt7S1XvZmZDapM0Ne6cUj1a+o+DbRL2gRcBfwQ2FdybLYzYnlEVCKi0tHRUaIsMzMro8zr6HuASYXticCuYoeI2AvMB1B2R6nH8q9jBxtrZmZDq8yMfgMwVdIUSaOBecDaYgdJJ+RtAB8FHsjDf9CxZmY2tAad0UfEPklXAvcBbcCKiNgi6fK8fRkwDbhT0n5gK7BgoLFDcyrWDK14S+D29vZml2DWUtSKb2GvVCrR1dXV7DJsGElqydspmI0UkjZGRKVWm98Za2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOH/wiA25si/BLNvPr84xOzgOehtyDmaz5vLSjZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSWuVNBLmiNpu6RuSdfVaB8n6WuSHpK0RdL8Qtvjkh6RtEmSPx/QzGyYDXpTM0ltwFLgQqAH2CBpbURsLXS7AtgaEe+V1AFsl/SliHgxb58dEbsbXbyZmQ2uzIx+JtAdETvy4F4NzK3qE8AYZfeZPR7oA/Y1tFIzMzskZYJ+ArCzsN2T7yu6DZgG7AIeAT4WES/nbQGsk7RR0sJ6B5G0UFKXpK7e3t7SJ2BmZgMrE/S1Pg2i+gbj7wY2AScDM4DbJI3N286JiLOBi4ErJJ1X6yARsTwiKhFR6ejoKFO7mZmVUCboe4BJhe2JZDP3ovnA3ZHpBh4D3gQQEbvyf58G1pAtBZmZ2TApE/QbgKmSpkgaDcwD1lb1eRK4AEDSScBpwA5Jx0kak+8/DrgI2Nyo4s3MbHCDvuomIvZJuhK4D2gDVkTEFkmX5+3LgE8Bd0h6hGyp59qI2C3p9cCa/LNARwErI+LeIToXMzOrQa34eZ6VSiW6uvySezOzsiRtjIhKrTa/M9bMLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxJUKeklzJG2X1C3puhrt4yR9TdJDkrZIml92rJmZDa1Bg15SG7AUuBiYDnRKml7V7Qpga0ScCZwP3CxpdMmxZmY2hMrM6GcC3RGxIyJeBFYDc6v6BDBGkoDjgT5gX8mxZmY2hMoE/QRgZ2G7J99XdBswDdgFPAJ8LCJeLjkWAEkLJXVJ6urt7S1ZvpmZDaZM0KvGvqjafjewCTgZmAHcJmlsybHZzojlEVGJiEpHR0eJsszMrIwyQd8DTCpsTySbuRfNB+6OTDfwGPCmkmPNzGwIlQn6DcBUSVMkjQbmAWur+jwJXAAg6STgNGBHybFmZjaERg3WISL2SboSuA9oA1ZExBZJl+fty4BPAXdIeoRsuebaiNgNUGvs0JyKmZnVooiaS+ZNValUoqurq9llmJmNGJI2RkSlVpvfGWtmljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4koFvaQ5krZL6pZ0XY32T0jalH9tlrRf0vi87XFJj+Rt/nxAM7NhNuiHg0tqA5YCFwI9wAZJayNia3+fiPgM8Jm8/3uBayKir/Aws/s/LNzMzIZXmRn9TKA7InZExIvAamDuAP07gVWNKM7MzA5fmaCfAOwsbPfk+w4g6VhgDvCVwu4A1knaKGlhvYNIWiipS1JXb29vibLMzKyMMkGvGvuiTt/3At+tWrY5JyLOBi4GrpB0Xq2BEbE8IioRUeno6ChRlpmZlVEm6HuASYXticCuOn3nUbVsExG78n+fBtaQLQWZmdkwKRP0G4CpkqZIGk0W5murO0kaB7wD+Gph33GSxvR/D1wEbG5E4WZmVs6gr7qJiH2SrgTuA9qAFRGxRdLlefuyvOslwLqIeLYw/CRgjaT+Y62MiHsbeQJmZjYwRdRbbm+eSqUSXV1+yb2ZWVmSNkZEpVab3xlrZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeJKBb2kOZK2S+qWdF2N9k9I2pR/bZa0X9L4MmPNzGxoDRr0ktqApcDFwHSgU9L0Yp+I+ExEzIiIGcCfAd+JiL4yY83MbGiVmdHPBLojYkdEvAisBuYO0L8TWHWIY83MrMHKBP0EYGdhuyffdwBJxwJzgK8cwtiFkrokdfX29pYoy8zMyigT9KqxL+r0fS/w3YjoO9ixEbE8IioRUeno6ChRlpmZlVEm6HuASYXticCuOn3n8W/LNgc71szMhkCZoN8ATJU0RdJosjBfW91J0jjgHcBXD3asmZkNnVGDdYiIfZKuBO4D2oAVEbFF0uV5+7K86yXAuoh4drCxjT4JMzOrTxH1ltubp1KpRFdXV7PLMDMbMSRtjIhKrTa/M9bMLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHGD3qb4SCTV+mCsQ9eKdwg1syOHg76GMsEsyQFuZiPCEbd0M378eCQd9hfQkMeRxPjx45t8VcwsZUfcjH7Pnj0tNxNv9FKRmVnRETejNzM70pQKeklzJG2X1C3pujp9zpe0SdIWSd8p7H9c0iN5mz8f0MxsmA26dCOpDVgKXAj0ABskrY2IrYU+JwCfB+ZExJOSXlv1MLMjYnfjyjYzs7LKrNHPBLojYgeApNXAXGBroc+HgLsj4kmAiHi60YU2Stw4FhaPa3YZrxI3jm12CWaWsDJBPwHYWdjuAd5e1eeNwNGSvg2MAW6JiDvztgDWSQrgbyJiea2DSFoILAQ45ZRTSp/AwdJNe4fssQ9Ve3s7fYubXYWZpapM0Nd6SUj1y1ZGAW8FLgB+A/iepO9HxI+AcyJiV76c8w1Jj0bEAwc8YPYLYDlApVIZspfFNOoVN34dvZmNFGWejO0BJhW2JwK7avS5NyKezdfiHwDOBIiIXfm/TwNryJaCzMxsmJQJ+g3AVElTJI0G5gFrq/p8FThX0ihJx5It7WyTdJykMQCSjgMuAjY3rnwzMxvMoEs3EbFP0pXAfUAbsCIitki6PG9fFhHbJN0LPAy8DHwhIjZLej2wJn9D0ChgZUTcO1QnY2ZmB1IrrjNXKpXo6mrtl9x7jd7MWomkjRFRqdXmd8aamSXOQW9mljgHvZlZ4o64u1eWUfZukmX7eS3fzJrJQV+Dg9nMUuKlGzOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEtefdKSb3AE82uYxAnAv7A88bx9WwsX8/GGgnX89SI6KjV0JJBPxJI6qp3S1A7eL6ejeXr2Vgj/Xp66cbMLHEOejOzxDnoD93yZheQGF/PxvL1bKwRfT29Rm9mljjP6M3MEuegL0HSMzX2LZb0U0mbJG2V1NmM2kaCEtfvx5LuljS9qs9ZkkLSu4ev2tZWvJaS3pNfu1Py6/mcpNfW6RuSbi5s/2dJi4et8BYj6XWSVkv6Sf7/7z2S3pi3XSPpeUnjCv3Pl/RLST+U9Kik/yHpzfnP7yZJfZIey7//f807s9oc9IfnsxExA5gL/I2ko5tcz0jz2YiYERFTgS8D35JUfB1wJ7A+/9cKJF0A3ArMiYgn8927gT+tM+QF4P2SThyO+lqZso+GWwN8OyJ+KyKmA9cDJ+VdOoENwCVVQx+MiLOAs4DfBcbmP78zgLXAJ/Ltdw3HeRwMB30DRMSPgeeA9mbXMlJFxJeBdcCH4JX/Gf8A+AhwkaTXNK+61iLpXOB/Ab8TET8pNK0APihpfI1h+8ieULxmGEpsdbOBlyJiWf+OiNgUEQ9K+i3geOAG6kwwIuLXwCZgwjDU2hAO+gaQdDbw44h4utm1jHD/Arwp//4c4LE8yL4NvKdZRbWYY4CvAu+LiEer2p4hC/uP1Rm7FLi0uCRxhDoD2FinrRNYBTwInFZcCusnqR2YCjwwZBU2mIP+8FwjaTvwz8DiJteSguKnrXcCq/PvV+Plm34vAf8ELKjT/jngMkljqxsiYi9wJ3D10JU34s0DVkfEy8DdwH8otJ0r6WHgKeD/RMRTzSjwUDjoD89nI+I04IPAnV5eOGxnAdsktQG/D3xS0uNka9EXSxrTzOJaxMvAB4C3Sbq+ujEifgGsBP5TnfF/TfZL4rghqm8k2AK8tXqnpLeQzdS/kf/czePVE4wHI+ItwJuBP5E0Y+hLbQwHfQNExN1AF3BZs2sZqST9PnAR2Z/N7wIeiohJETE5Ik4FvgK8r4kltoyIeI7sycBLJdWa2f8V8MfAqBpj+4C7qP8XwZHgW8Axkv6of4ektwG3AIvzn7nJEXEyMEHSqcXBEfEj4C+Ba4ez6MPhoC/nWEk9ha+P1+jz58DHJfmaHqje9bum/+WVwB8C74yIXrJZ1Jqqx/gK+RO19kpgzwFukDS3qm032fU7ps7wm8nuxnhEiuxdopcAF+Yvr9xCtvR6Pgf+3K0hm9lXWwacJ2nKEJbaMH5nrJlZ4jz7NDNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEvf/AewB7r+R3qohAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CART results on 30% test set \n",
      "\n",
      "0.9933065595716198\n",
      "\n",
      "CART accuracy test: \n",
      "\n",
      "0.9933065595716198\n",
      "[[349   0]\n",
      " [  5 393]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.99      1.00      0.99       349\n",
      "  Normal_traffic       1.00      0.99      0.99       398\n",
      "\n",
      "        accuracy                           0.99       747\n",
      "       macro avg       0.99      0.99      0.99       747\n",
      "    weighted avg       0.99      0.99      0.99       747\n",
      "\n",
      "\n",
      "CART results on final 30% validation \n",
      "\n",
      "\n",
      "CART accuracy validation: \n",
      "\n",
      "0.9896907216494846\n",
      "[[559   1]\n",
      " [ 10 497]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.98      1.00      0.99       560\n",
      "  Normal_traffic       1.00      0.98      0.99       507\n",
      "\n",
      "        accuracy                           0.99      1067\n",
      "       macro avg       0.99      0.99      0.99      1067\n",
      "    weighted avg       0.99      0.99      0.99      1067\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " Logistic Regression results on 30% test set \n",
      "\n",
      "0.6452476572958501\n",
      "\n",
      "Logistic Regression accuracy test: \n",
      "\n",
      "0.6452476572958501\n",
      "[[345   4]\n",
      " [261 137]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.57      0.99      0.72       349\n",
      "  Normal_traffic       0.97      0.34      0.51       398\n",
      "\n",
      "        accuracy                           0.65       747\n",
      "       macro avg       0.77      0.67      0.62       747\n",
      "    weighted avg       0.78      0.65      0.61       747\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " KNeighbors results on 30% test set \n",
      "\n",
      "0.9866131191432396\n",
      "\n",
      "K Neighbors accuracy test: \n",
      "\n",
      "0.9866131191432396\n",
      "[[348   1]\n",
      " [  9 389]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.97      1.00      0.99       349\n",
      "  Normal_traffic       1.00      0.98      0.99       398\n",
      "\n",
      "        accuracy                           0.99       747\n",
      "       macro avg       0.99      0.99      0.99       747\n",
      "    weighted avg       0.99      0.99      0.99       747\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      " Linear Discriminant Analysis results on 30% test set \n",
      "\n",
      "0.891566265060241\n",
      "\n",
      "Linear Discriminant Analysis accuracy test: \n",
      "\n",
      "0.891566265060241\n",
      "[[346   3]\n",
      " [ 78 320]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Abnormal_Traffic       0.82      0.99      0.90       349\n",
      "  Normal_traffic       0.99      0.80      0.89       398\n",
      "\n",
      "        accuracy                           0.89       747\n",
      "       macro avg       0.90      0.90      0.89       747\n",
      "    weighted avg       0.91      0.89      0.89       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from six import StringIO \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os     \n",
    "\n",
    "# import dataset\n",
    "dataset = pandas.read_csv(\"Master_ICMP_Attack.csv\")\n",
    "\n",
    "#print (dataset.shape)\n",
    "\n",
    "# head\n",
    "#print(dataset.head(20))\n",
    "\n",
    "# descriptions\n",
    "#print(dataset.describe())\n",
    "\n",
    "# class distribution\n",
    "#print(dataset.groupby('label').size())\n",
    "\n",
    "# split dataset\n",
    "array = dataset.values\n",
    "print (array)\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "validation_size = 0.30\n",
    "seed = 42\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "X_train_set, X_test, Y_train_set, Y_test = model_selection.train_test_split(X_train, Y_train, test_size=validation_size, random_state=seed)\n",
    "\n",
    "# Test options and evaluation metric\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Fit algorithm model\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s Accuracy: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "\n",
    "#Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n CART results on 30% test set \\n\")\n",
    "# Create Decision Tree classifer object\n",
    "cart = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "cart.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'finalized_DT_model.sav'\n",
    "joblib.dump(cart, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = cart.predict(X_test)\n",
    "print(\"\\nCART accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nCART results on final 30% validation \\n\")\n",
    "newcart = DecisionTreeClassifier()\n",
    "newcart.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newcart.predict(X_validation)\n",
    "print(\"\\nCART accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n",
    "\n",
    "# Testing For Logistic Regression\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n Logistic Regression results on 30% test set \\n\")\n",
    "# Create Logistic Regression classifer object\n",
    "logistic = LogisticRegression()\n",
    "# Train Logistic Regression Classifer\n",
    "logistic.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'logistic_finalized_DT_model.sav'\n",
    "joblib.dump(logistic, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = logistic.predict(X_test)\n",
    "print(\"\\nLogistic Regression accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc, zero_division=0))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nLogistic Regression results on final 30% validation \\n\")\n",
    "newlogistic = DecisionTreeClassifier()\n",
    "newlogistic.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newlogistic.predict(X_validation)\n",
    "print(\"\\nLogistic Regression accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n",
    "\n",
    "# Testing For KNeighbors\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n KNeighbors results on 30% test set \\n\")\n",
    "# Create K Neighbors classifer object\n",
    "KNeighbors = KNeighborsClassifier()\n",
    "# Train KNeighbors Classifer\n",
    "KNeighbors.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'kneighbors_finalized_DT_model.sav'\n",
    "joblib.dump(KNeighbors, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = KNeighbors.predict(X_test)\n",
    "print(\"\\nK Neighbors accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc, zero_division=0))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nK Neighbors results on final 30% validation \\n\")\n",
    "newKNeighbors = DecisionTreeClassifier()\n",
    "newKNeighbors.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newKNeighbors.predict(X_validation)\n",
    "print(\"\\nK Neighbors accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n",
    "\n",
    "# Testing For Linear Discriminant Analysis\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "print(\"\\n Linear Discriminant Analysis results on 30% test set \\n\")\n",
    "# Create Logistic Regression classifer object\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "# Train Linear Discriminant Analysis Classifer\n",
    "lda.fit(X_train_set, Y_train_set)\n",
    "#saving the model using joblib \n",
    "filename = 'lda_finalized_DT_model.sav'\n",
    "joblib.dump(lda, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print (result)\n",
    "#Predict the response for test dataset\n",
    "predictions_rfc = lda.predict(X_test)\n",
    "print(\"\\nLinear Discriminant Analysis accuracy test: \\n\")\n",
    "print(accuracy_score(Y_test, predictions_rfc))\n",
    "print(confusion_matrix(Y_test, predictions_rfc))\n",
    "print(classification_report(Y_test, predictions_rfc, zero_division=0))\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(\"\\nLinear Discriminant Analysis results on final 30% validation \\n\")\n",
    "newlda = DecisionTreeClassifier()\n",
    "newlda.fit(X_train_set, Y_train_set)\n",
    "newpredictions_rfc = newlda.predict(X_validation)\n",
    "print(\"\\nLinear Discriminant Analysis accuracy validation: \\n\")\n",
    "print(accuracy_score(Y_validation, newpredictions_rfc))\n",
    "print(confusion_matrix(Y_validation, newpredictions_rfc))\n",
    "print(classification_report(Y_validation, newpredictions_rfc))\n",
    "df = dataset.reset_index(drop = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9faba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045fb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
